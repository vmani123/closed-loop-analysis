{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Hoc Analysis Before 11/5/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "import itertools\n",
    "import math\n",
    "import seaborn as sns\n",
    "import statistics \n",
    "from collections import OrderedDict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tk root\n",
    "root = Tk()\n",
    "# Hide the main window\n",
    "root.withdraw()\n",
    "root.call('wm', 'attributes', '.', '-topmost', True)\n",
    "infiles = filedialog.askopenfilename(multiple=True, title='load posthoc-predictions.npy')\n",
    "\n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "Random_List = [] #creates a array known as random list \n",
    "for f in range(len(infiles)):\n",
    "    arr = np.load(infiles[f])\n",
    "    Random_List.extend(arr) \n",
    "print(Random_List)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define the number of elements in each row\n",
    "num_elements_per_row = 17\n",
    "\n",
    "# Print Random_List with each row having 17 elements\n",
    "for i in range(0, len(Random_List), num_elements_per_row):\n",
    "    row = Random_List[i:i+num_elements_per_row]\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Time of Video in deciseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video is 0 deciseconds, which is 0.0 minutes, which is 0 frames\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "duration_in_deciseconds = len(Random_List)\n",
    "duration_in_minutes = duration_in_deciseconds / 600\n",
    "duration_in_frames = duration_in_deciseconds * 3\n",
    "\n",
    "print('This video is', duration_in_deciseconds, 'deciseconds, which is', duration_in_minutes, 'minutes, which is', duration_in_frames, 'frames')\n",
    "print(Random_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Integration (deciseconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "BehaviorTime = []\n",
    "\n",
    "for index, value in enumerate(Random_List):\n",
    "    BehaviorTime.append((value, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(BehaviorTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensures you only analyze expected length of  Session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "length_of_session = (int(input(\"How long was the session in minutes?\"))) * 600\n",
    "print(length_of_session)\n",
    "BehaviorTime = BehaviorTime[:(length_of_session+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Long is the Original Video File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video is  0  deciseconds, which is 0.0 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('This video is ', len(BehaviorTime), ' deciseconds, which is', (len(BehaviorTime)/600), 'minutes' )\n",
    "print()\n",
    "#print(BehaviorTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Duration, Frames, Stim Count, Start Time, End Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [650]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     time\u001b[38;5;241m=\u001b[39m z[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m behavior_type_and_duration \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m current_behavior \u001b[38;5;241m=\u001b[39m \u001b[43mBehaviorTime\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m current_time \u001b[38;5;241m=\u001b[39m BehaviorTime[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]  \n\u001b[1;32m      7\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for z in BehaviorTime:\n",
    "    behavior = z[0]\n",
    "    time= z[1]\n",
    "behavior_type_and_duration = []\n",
    "current_behavior = BehaviorTime[0][0]\n",
    "current_time = BehaviorTime[0][1]  \n",
    "duration = 1\n",
    "stim_count=0\n",
    "frames = 0\n",
    "\n",
    "for behavior, time in BehaviorTime:\n",
    "    start_time= current_time\n",
    "    if behavior == current_behavior:\n",
    "        duration += 1\n",
    "      \n",
    "    else:\n",
    "        if duration==1:\n",
    "            end_time=start_time+1\n",
    "        else:\n",
    "            end_time= start_time + duration\n",
    "        frames= duration*3\n",
    "        stim_count= round(duration/3)\n",
    "        behavior_type_and_duration.append((current_behavior, duration,frames,stim_count,start_time, end_time))\n",
    "        current_behavior = behavior\n",
    "        current_time = time\n",
    "        start_time= time\n",
    "        duration = 1\n",
    "        end_time= time+1\n",
    "        \n",
    "# Append the final (current_behavior, current_time, count) tuple outside the loop\n",
    "behavior_type_and_duration.append((current_behavior, duration, frames, stim_count, start_time, end_time))\n",
    "\n",
    "# Make a copy of the original behavior_type_and_duration list\n",
    "behaviortdt= list(behavior_type_and_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(behaviortdt)\n",
    "#print(len(behaviortdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length_of_session = (int(input(\"How long was the session in minutes?\"))) * 600 \n",
    "#print(length_of_session) \n",
    "behaviortdt = [tup for tup in behaviortdt if tup[4] <= 39000]\n",
    "behaviortdt=[tup for tup in behaviortdt if tup[1]<= 5]\n",
    "count_greater_than_5 = sum(1 for tup in behaviortdt if tup[1] > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This video is ', behaviortdt[-1][-1], ' deciseconds, which is', (behaviortdt[-1][-1]/600), 'minutes' )\n",
    "print(\"Number of tuples with a second element greater than 5 :\", count_greater_than_5)\n",
    "print()\n",
    "print(behaviortdt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for current_behavior, duration, frames, start_time, current_time in behaviortdt:\n",
    "    if duration "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This now have Behavior, duration, frame rate, start Time, and end time in one array grouped into tuples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Bout Count to the Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enumerated_behaviortdt = []\n",
    "behavior_index = {}  # Dictionary to store behavior and its corresponding index\n",
    "\n",
    "for behavior, duration, frames, stim_count, start_time, end_time in behaviortdt:\n",
    "    if behavior not in behavior_index:\n",
    "        behavior_index[behavior] = 1\n",
    "    else:\n",
    "        behavior_index[behavior] += 1\n",
    "    \n",
    "    bout = behavior_index[behavior]\n",
    "    enumerated_behaviortdt.append((behavior,stim_count,frames, bout, duration,start_time,end_time))\n",
    "\n",
    "print(enumerated_behaviortdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming enumerated_behaviortdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BCBDT = []\n",
    "\n",
    "# Calculate durations and update BCBDT\n",
    "#for behavior, duration, frames, bout, start_time, end_time in enumerated_behaviortdt:\n",
    "    #stim_count = round(duration / 3)\n",
    "    #if stim_count < 1:\n",
    "        #stim_count = 0\n",
    "    #if stim_count > 0:\n",
    "        #BCBDT.append((behavior, duration, frames, bout, stim_count, start_time, end_time))\n",
    "\n",
    "# Print the modified BCBDT\n",
    "#print(\"Modified BCBDT:\", BCBDT)\n",
    "\n",
    "# Assign enumerated_behaviortdt to BCBDST\n",
    "BCBDST = enumerated_behaviortdt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_labels = {\n",
    "    0.0: \"Right Turns\",\n",
    "    1.0: \"Left Turns\",\n",
    "    2.0: \"Locomotion\",\n",
    "    3.0: \"Face Groom\",\n",
    "    4.0: \"All Other Groom\",\n",
    "    5.0: \"All Other\",\n",
    "}\n",
    "\n",
    "bdbt_dict = {}  # Dictionary to store lists of behaviors\n",
    "\n",
    "for behavior,stim_count,frames, bout, duration,start_time,end_time in BCBDST:\n",
    "    behavior_label = behavior_labels.get(behavior, \"Unknown Behavior\")\n",
    "    if behavior_label not in bdbt_dict:\n",
    "        bdbt_dict[behavior_label] = []\n",
    "    bdbt_dict[behavior_label].append((behavior, stim_count, frames, bout, duration, start_time,end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(bdbt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = bdbt_dict.keys()\n",
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bdbt_dict is a dictionary that contains the enumerated behaviortdt . It contains keys: \n",
    "    'All Other', 'Left Turns', 'Locomotion', 'Face Groom', 'All Other Groom', 'Right Turns'\n",
    "The tuples are structed as behavior, stim_count, frame, bout,duration, start time, end time (decieconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stim Count and Average Duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "stimcount_by_key = {}\n",
    "\n",
    "def round_float(value):\n",
    "    return round(value, 3)\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    stimcount = [tuple_item[1] for tuple_item in tuples_list]\n",
    "    sum_of_stimcount = sum(stimcount)\n",
    "    stimcount_by_key[key] = sum_of_stimcount\n",
    "\n",
    "table_data = [(key, round_float(sum_value)) for key, sum_value in stimcount_by_key.items()]\n",
    "headers = [\"Key\", \"Total Number of Stimulations\"]\n",
    "\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)\n",
    "\n",
    "average_duration_by_key = {}\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    durations = [tuple_item[4] for tuple_item in tuples_list]\n",
    "    average_duration = ((sum(durations) / len(durations))/10)\n",
    "    average_duration_by_key[key] = round_float(average_duration)\n",
    "\n",
    "table_data = [(key, avg_duration) for key, avg_duration in average_duration_by_key.items()]\n",
    "headers = [\"Key\", \"Average Duration(seconds)\"]\n",
    "\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)\n",
    "\n",
    "stim_block_stim_count_by_key = {}\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    sum_of_stimcount = 0\n",
    "    for tuple_item in tuples_list:\n",
    "        if tuple_item[5]> 3000 and tuple_item[6] <= 21000:  \n",
    "            sum_of_stimcount += tuple_item[1]\n",
    "    stim_block_stim_count_by_key[key] = sum_of_stimcount\n",
    "\n",
    "table_data = [(key, round_float(sum_value)) for key, sum_value in stim_block_stim_count_by_key.items()]\n",
    "headers = [\"Key\", \"Total Stimulations during 30-Min Stim Block\"]\n",
    "#for (key, value) in stim_block_stim_count_by_key:\n",
    "    #print(key)\n",
    "    #print(value)\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)\n",
    "\n",
    "average_duration_30min_by_key = {}\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    total_duration = 0  # Initialize the total duration to 0\n",
    "    count = 0  # Initialize a count variable to track the number of valid tuples\n",
    "    \n",
    "    for tuple_item in tuples_list:\n",
    "        if tuple_item[5] > 3000 and tuple_item[6] <= 21000:  # Check the conditions\n",
    "            total_duration += tuple_item[4]  # Add the duration to the total\n",
    "            count += 1  # Increment the count\n",
    "            \n",
    "    if count > 0:\n",
    "        average_duration = round(((total_duration / count)/10), 2)  # Calculate average and round it\n",
    "    else:\n",
    "        average_duration = 0  # Set average to 0 if there are no valid tuples\n",
    "    \n",
    "    average_duration_30min_by_key[key] = average_duration\n",
    "\n",
    "# Printing the results in a tabular format\n",
    "table_data = [(key, avg_duration) for key, avg_duration in average_duration_30min_by_key.items()]\n",
    "headers = [\"Key\", \"Average Duration During 30 Min Stim Block (seconds)\"]\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Number of Bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bout_by_key = {}\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    bouts = [tuple_item[3] for tuple_item in tuples_list]\n",
    "    sum_of_bouts = len(bouts)\n",
    "    bout_by_key[key] = sum_of_bouts\n",
    "\n",
    "table_data = [(key, sum_value) for key, sum_value in bout_by_key.items()]\n",
    "headers = [\"Key\", \"Total Bouts\"]\n",
    "\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)\n",
    "\n",
    "stim_block_bout_count_by_key = {}\n",
    "\n",
    "for key, tuples_list in bdbt_dict.items():\n",
    "    bout_count = sum(1 for tuple_item in tuples_list if 3000 < tuple_item[5] and tuple_item[6] <= 21000)\n",
    "    stim_block_bout_count_by_key[key] = bout_count\n",
    "\n",
    "table_data = [(key, count) for key, count in stim_block_bout_count_by_key.items()]\n",
    "headers = [\"Key\", \"30 minute Stim Block Bout Count\"]\n",
    "\n",
    "table = tabulate(table_data, headers, tablefmt=\"pretty\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for file_path in infiles: # if taking from Z Drive \n",
    "    folders = (os.path.dirname(file_path)).split('/')\n",
    "    print(folders)\n",
    "    print(len(folders))\n",
    "    if len(folders) >= 4:  # Check if there are at least 4 elements in the list\n",
    "        folder_name = folders[-1].lower()\n",
    "        print(folder_name)\n",
    "        fol = re.split(r'[-\\s]+', folder_name)\n",
    "\n",
    "        if len(fol) >= 2:  # Check if there are at least 2 elements in the 'fol' list\n",
    "            if fol[1] == 'face':\n",
    "                # Merge 'face' and 'groom' into a single folder\n",
    "                fol[1] = 'face groom'\n",
    "                fol.pop(2)\n",
    "\n",
    "            print(fol)\n",
    "            print(len(fol))\n",
    "        else:\n",
    "            print(\"Folder name does not contain at least two elements.\")\n",
    "    else:\n",
    "        print(\"Not enough elements in the folders list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type = \"Stim Session\"\n",
    "sham_session = \"n\"  # Initialize sham_session to \"n\" by default\n",
    "\n",
    "# Check if either \"Sham\" or 'sham' is in the string 'fol'\n",
    "if \"Sham\" in fol or 'sham' in fol:\n",
    "    sham_session = \"y\"\n",
    "\n",
    "# Check if sham_session (converted to lowercase) is \"y\"\n",
    "if sham_session.lower() == \"y\":\n",
    "    trial_type = \"Sham Session\"\n",
    "\n",
    "print(sham_session)\n",
    "print(trial_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_mapping = {\n",
    "    0: \"Right Turn \",\n",
    "    1: \"Left Turn \",\n",
    "    2: \"Locomotion \",\n",
    "    3: \"Face Groom \",\n",
    "    4: \"All Other Groom \",\n",
    "    5: \"All Other \"\n",
    "}\n",
    "\n",
    "print(\"Please select the behavior of interest:\")\n",
    "for key, value in behavior_mapping.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "# Assuming fol[1] contains the behavior label\n",
    "fol_label = fol[1].lower()  # Convert to lowercase for case-insensitive comparison\n",
    "\n",
    "# Check if the fol_label is \"rt\" or \"RT\" and set behavior_of_interest_1 accordingly\n",
    "if fol_label == 'rt':\n",
    "    behavior_of_interest_1 = 0\n",
    "elif fol_label =='locomotion':\n",
    "    behavior_of_interest_1 = 2\n",
    "elif fol_label == 'left turn':\n",
    "    behavior_of_interest_1=1\n",
    "elif fol_label=='face groom':\n",
    "    behavior_of_interest_1=3\n",
    "elif fol_label== 'all other groom':\n",
    "    behavior_of_interest_1=4\n",
    "elif fol_label=='all other':\n",
    "    behavior_of_interest_1=5\n",
    "    \n",
    "\n",
    "behavior_name_2 = behavior_mapping.get(behavior_of_interest_1, \"Unknown\")\n",
    "\n",
    "print(\"Selected behavior of interest:\", behavior_name_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Fiber Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(fol)>=3:\n",
    "    print(len(fol))\n",
    "    fol_label = fol[2].lower() \n",
    "    if fol_label=='bilateral':\n",
    "        type_of_fiber_connection = 'Bilateral'\n",
    "    elif fol_label=='contralateral'or fol_label=='contra':\n",
    "        type_of_fiber_connection = 'Contralateral'\n",
    "    elif fol_label=='ipsilateral'or fol_label=='ipsi':\n",
    "        type_of_fiber_connection = 'Ipsilateral'\n",
    "    else:\n",
    "        type_of_fiber_connection = 'Bilateral'\n",
    "else:\n",
    "    type_of_fiber_connection = 'Bilateral'\n",
    "\n",
    "\n",
    "#selection = input(\"Please enter the type of fiber connection for the trial (B for Bilateral, I for Ipsilateral, C for Contralateral): \")\n",
    "\n",
    "\n",
    "print(\"Selected type of fiber connection:\", type_of_fiber_connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_dict = {}\n",
    "\n",
    "for key, value_list in bdbt_dict.items():\n",
    "    rounded_values = [\n",
    "        (\n",
    "            round(v[0]),     # Rounding and converting to integer\n",
    "            v[1], v[2], v[3], v[4],\n",
    "            round(v[5], 2),  # Rounding the sixth float value\n",
    "            round(v[6], 2)   # Rounding the seventh float value\n",
    "        )\n",
    "        for v in value_list\n",
    "    ]\n",
    "    rounded_dict[key] = rounded_values\n",
    "\n",
    "#print(rounded_dict)\n",
    "\n",
    "bdbt_dict=rounded_dict\n",
    "#print(bdbt_dict)\n",
    "\n",
    "# Convert values to JSON strings\n",
    "\n",
    "import json\n",
    "json_data = {key: json.dumps(value) for key, value in bdbt_dict.items()}\n",
    "bdbt_dict=json_data \n",
    "#print(bdbt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each file in infiles\n",
    "for file_path in infiles: # if taking from K Drive on home machine\n",
    "    folders = (os.path.dirname(file_path)).split('/')\n",
    "    #print(folders)\n",
    "    # Extract the mouse name from the file path\n",
    "    mouse_name = folders[7].split('-')[0]\n",
    "    # Extract the genotype from the file path\n",
    "    genotype = folders[7].split('-')[1]\n",
    "    # Extract the date from the file path\n",
    "    date = folders[-1].split('-')[0]\n",
    "#for file_path in infiles: # if taking from Z Drive \n",
    "    #folders = (os.path.dirname(file_path)).split('/')\n",
    "    #print(folders)\n",
    "    # Extract the mouse name from the file path\n",
    "    #mouse_name = folders[4].split('-')[0]\n",
    "    # Extract the genotype from the file path\n",
    "    #genotype = folders[4].split('-')[1]\n",
    "    # Extract the date from the file path\n",
    "    #date = folders[-1].split('-')[0]\n",
    "#for file_path in infiles:   #if taking files from D drive\n",
    "    #folders = (os.path.dirname(file_path)).split('/')\n",
    "    #print(folders)\n",
    "    # Extract the mouse name from the file path\n",
    "    #mouse_name = folders[6].split('-')[0]\n",
    "    # Extract the genotype from the file path\n",
    "    #genotype = folders[6].split('-')[1]\n",
    "    # Extract the date from the file path\n",
    "    #date = folders[-1].split('-')[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdbt_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df=[]\n",
    "session_number=0\n",
    "#If on home machine\n",
    "#db_file_path = \"/Users/kaycei/K on Server (NoMachine)/KayCei/Naturalistic_cleaned.pkl\"\n",
    "#If on Lab Computer\n",
    "db_file_path=\"Z:/KayCei/Vik practice/VikPracticeDatabase.pkl\"\n",
    " # Check if the pickle file exists\n",
    "if os.path.exists(db_file_path):\n",
    "    # If the file exists, load the existing DataFrame\n",
    "    with open(db_file_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "else:\n",
    "    # If the file doesn't exist, create a new DataFrame\n",
    "    df = pd.DataFrame(columns=[\"Mouse\",\"Genotype\",\"Date\",\"Selected Behavior\",\"Session Type\",\"Session Number\",\"Fiber Connection\",\n",
    "                               \"Right Turn Array\",\"Total Right Turn Bout Count\",\"Average Duration of Right Turn(seconds)\",\n",
    "                               \"Total Right Turn Bouts in Stim Block\",\"Right Turn Average Duration in Stim Block(seconds)\",\n",
    "                               \"Left Turn Array\",\"Total Left Turn Bout Count\",\"Average Duration of Left Turn(seconds)\",\n",
    "                               \"Total Left Turn Bouts in Stim Block\",\"Left Turn Average Duration in Stim Block(seconds)\",\n",
    "                               \"Locomotion Array\",\"Total Locomotion Bout Count\",\"Average Duration of Locomotion(seconds)\",\n",
    "                               \"Total Locomotion Bouts in Stim Block\",\"Locomotion Average Duration in Stim Block(seconds)\",\n",
    "                               \"Face Groom Array\",\"Total Face Groom Bout Count\",\"Average Duration of Face Groom(seconds)\",\n",
    "                               \"Total Face Groom Bouts in Stim Block\",\"Face Groom Average Duration in Stim Block(seconds)\",\n",
    "                               \"All Other Groom Array\",\"Total All Other Groom Bout Count\",\"Average Duration of All Other Groom(seconds)\",\n",
    "                               \"Total All Other Groom Bouts in Stim Block\",\"All Other Groom Average Duration in Stim Block(seconds)\",\n",
    "                               \"All Other Array\",\"Total All Other Bout Count\",\"Average Duration of All Other(seconds)\",\n",
    "                               \"Total All Other Bouts in Stim Block\",\"All Other Average Duration in Stim Block(seconds)\",\n",
    "                              ])\n",
    "new_animal_data = {\n",
    "        \"Mouse\":mouse_name,\n",
    "        \"Genotype\":genotype,\n",
    "        \"Date\":date,\n",
    "        \"Selected Behavior\":behavior_name_2,\n",
    "        \"Session Type\":trial_type,  \n",
    "        \"Session Number\":session_number,\n",
    "        \"Fiber Connection\":type_of_fiber_connection,\n",
    "        \"Right Turn Array\":bdbt_dict.get('Right Turns'),\n",
    "        \"Total Right Turn Bout Count\":bout_by_key.get('Right Turns'),\n",
    "        \"Average Duration of Right Turn(seconds)\":average_duration_by_key.get('Right Turns'),\n",
    "        \"Total Right Turn Bouts in Stim Block\":stim_block_bout_count_by_key.get('Right Turns'),\n",
    "        \"Right Turn Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('Right Turns'),\n",
    "        \"Left Turn Array\":bdbt_dict.get('Left Turns'),\n",
    "        \"Total Left Turn Bout Count\":bout_by_key.get('Left Turns'),\n",
    "        \"Average Duration of Left Turn(seconds)\":average_duration_by_key.get('Left Turns'),\n",
    "        \"Total Left Turn Bouts in Stim Block\":stim_block_bout_count_by_key.get('Left Turns'),\n",
    "        \"Left Turn Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('Left Turns'),\n",
    "        \"Locomotion Array\":bdbt_dict.get('Locomotion'),\n",
    "        \"Total Locomotion Bout Count\":bout_by_key.get('Locomotion'),\n",
    "        \"Average Duration of Locomotion(seconds)\":average_duration_by_key.get('Locomotion'),\n",
    "        \"Total Locomotion Bouts in Stim Block\":stim_block_bout_count_by_key.get('Locomotion'),\n",
    "        \"Locomotion Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('Locomotion'),\n",
    "        \"Face Groom Array\":bdbt_dict.get('Face Groom'),\n",
    "        \"Total Face Groom Bout Count\":bout_by_key.get('Face Groom'),\n",
    "        \"Average Duration of Face Groom(seconds)\":average_duration_by_key.get('Face Groom'),\n",
    "        \"Total Face Groom Bouts in Stim Block\":stim_block_bout_count_by_key.get('Face Groom'),\n",
    "        \"Face Groom Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('Face Groom'),\n",
    "        \"All Other Groom Array\":bdbt_dict.get('All Other Groom'),\n",
    "        \"Total All Other Groom Bout Count\":bout_by_key.get('All Other Groom'),\n",
    "        \"Average Duration of All Other Groom(seconds)\":average_duration_by_key.get('All Other Groom'),\n",
    "        \"Total All Other Groom Bouts in Stim Block\":stim_block_bout_count_by_key.get('All Other Groom'),\n",
    "        \"All Other Groom Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('All Other Groom'),\n",
    "        \"All Other Array\":bdbt_dict.get('All Other'),\n",
    "        \"Total All Other Bout Count\":bout_by_key.get('All Other'),\n",
    "        \"Average Duration of All Other(seconds)\":average_duration_by_key.get('All Other'),\n",
    "        \"Total All Other Bouts in Stim Block\":stim_block_bout_count_by_key.get('All Other'),\n",
    "        \"All Other Average Duration in Stim Block(seconds)\":average_duration_30min_by_key.get('All Other'),}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def rearrange_session_numbers(filtered_df):\n",
    "    # Sort filtered DataFrame by date\n",
    "    filtered_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "    # Assign session numbers based on the sorted order\n",
    "    filtered_df['Session Number'] = range(1, len(filtered_df) + 1)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def add_animal_to_database(db_file_path, new_animal_data, mouse_name, genotype, date, behavior_name_2, trial_type, type_of_fiber_connection,filtered_df):\n",
    "    # Check if the pickle file exists\n",
    "    if os.path.exists(db_file_path):\n",
    "        # If the file exists, load the existing DataFrame\n",
    "        with open(db_file_path, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "    else:\n",
    "        # If the file doesn't exist, create a new DataFrame\n",
    "        df = pd.DataFrame(columns=[\"Mouse\",\"Genotype\",\"Date\",\"Selected Behavior\",\"Session Type\",\"Session Number\",\"Fiber Connection\",\n",
    "                                   \"Right Turn Array\",\"Total Right Turn Bout Count\",\"Average Duration of Right Turn(seconds)\",\n",
    "                                   \"Total Right Turn Bouts in Stim Block\",\"Right Turn Average Duration in Stim Block(seconds)\",\n",
    "                                   \"Left Turn Array\",\"Total Left Turn Bout Count\",\"Average Duration of Left Turn(seconds)\",\n",
    "                                   \"Total Left Turn Bouts in Stim Block\",\"Left Turn Average Duration in Stim Block(seconds)\",\n",
    "                                   \"Locomotion Array\",\"Total Locomotion Bout Count\",\"Average Duration of Locomotion(seconds)\",\n",
    "                                   \"Total Locomotion Bouts in Stim Block\",\"Locomotion Average Duration in Stim Block(seconds)\",\n",
    "                                   \"Face Groom Array\",\"Total Face Groom Bout Count\",\"Average Duration of Face Groom(seconds)\",\n",
    "                                   \"Total Face Groom Bouts in Stim Block\",\"Face Groom Average Duration in Stim Block(seconds)\",\n",
    "                                   \"All Other Groom Array\",\"Total All Other Groom Bout Count\",\"Average Duration of All Other Groom(seconds)\",\n",
    "                                   \"Total All Other Groom Bouts in Stim Block\",\"All Other Groom Average Duration in Stim Block(seconds)\",\n",
    "                                   \"All Other Array\",\"Total All Other Bout Count\",\"Average Duration of All Other(seconds)\",\n",
    "                                   \"Total All Other Bouts in Stim Block\",\"All Other Average Duration in Stim Block(seconds)\",\n",
    "                                  ])\n",
    "\n",
    "    # Check if the combination of mouse_name, genotype, and date already exists in the DataFrame\n",
    "    existing_animal = df[(df['Mouse'] == mouse_name) & (df['Genotype'] == genotype) & (df['Date'] == date)]\n",
    "    \n",
    "    if not existing_animal.empty:\n",
    "        print(\"Animal with the same name, genotype, and date already exists. Skipping addition.\")\n",
    "        return\n",
    "    # Store the original indices of the DataFrame\n",
    "    original_indices = df.index\n",
    "    \n",
    "    # Filter the DataFrame based on 'Animal Name', 'Genotype', and 'Session Type'\n",
    "    filtered_df = df[(df['Mouse'] == new_animal_data['Mouse']) & \n",
    "                 (df['Genotype'] == new_animal_data['Genotype']) & \n",
    "                 (df['Session Type'] == new_animal_data['Session Type'])&\n",
    "                 (df['Selected Behavior'] == new_animal_data['Selected Behavior'])&\n",
    "                 (df['Fiber Connection'] == new_animal_data['Fiber Connection'])]\n",
    "    # Print the filtered DataFrame\n",
    "    #print(filtered_df)\n",
    "\n",
    "    # If the filtered DataFrame is not empty, set the 'Session Number' to the number of occurrences plus 1\n",
    "    if not filtered_df.empty:\n",
    "        session_number = int(filtered_df.shape[0] + 1)\n",
    "    else:\n",
    "        # If the combination is new, set 'Session Number' to 1\n",
    "        session_number = int(1)\n",
    "\n",
    "    # Append the new animal data to the DataFrame\n",
    "    new_animal_data['Session Number'] = session_number\n",
    "    new_row = pd.DataFrame([new_animal_data])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    # Rearrange session numbers based on date only for the filtered DataFrame if it's not empty\n",
    "    if not filtered_df.empty:\n",
    "        filtered_df = rearrange_session_numbers(filtered_df)\n",
    "        # Use the original indices to update the session numbers in the original DataFrame\n",
    "        df.loc[original_indices.intersection(filtered_df.index), 'Session Number'] = filtered_df['Session Number']\n",
    "    else:\n",
    "        print(\"No data found for rearrangement. Skipping session number rearrangement.\")\n",
    "\n",
    "    # Save the updated DataFrame back to the pickle file\n",
    "    with open(db_file_path, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "    print(\"New animal added to the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_animal_to_database(db_file_path, new_animal_data, mouse_name, genotype, date, behavior_name_2, trial_type, type_of_fiber_connection,filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data from the PKL file into a DataFrame\n",
    "data = pd.read_pickle(db_file_path)\n",
    "\n",
    "# Group the data by unique combinations of values across multiple columns\n",
    "grouped = data.groupby(['Mouse', 'Genotype', 'Session Type', 'Selected Behavior', 'Fiber Connection'])\n",
    "\n",
    "# Define a function to sort each group by date and assign session numbers\n",
    "def assign_session_numbers(group):\n",
    "    # Sort the group by date\n",
    "    group_sorted = group.sort_values(by='Date')\n",
    "    # Assign session numbers based on the order of rows within the sorted group\n",
    "    group_sorted['Session Number'] = range(1, len(group_sorted) + 1)\n",
    "    return group_sorted\n",
    "\n",
    "# Apply the function to each group\n",
    "sorted_data = grouped.apply(assign_session_numbers)\n",
    "\n",
    "# Reset the index of sorted_data to ensure correct alignment\n",
    "sorted_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Iterate over rows in sorted_data and update corresponding rows in data\n",
    "for index, row in sorted_data.iterrows():\n",
    "    # Find matching rows in data based on common columns\n",
    "    mask = (data['Mouse'] == row['Mouse']) & (data['Genotype'] == row['Genotype']) & \\\n",
    "           (data['Session Type'] == row['Session Type']) & \\\n",
    "           (data['Selected Behavior'] == row['Selected Behavior']) & \\\n",
    "           (data['Fiber Connection'] == row['Fiber Connection']) & \\\n",
    "           (data['Date'] == row['Date'])\n",
    "    # Update session number in data based on the match\n",
    "    data.loc[mask, 'Session Number'] = row['Session Number']\n",
    "\n",
    "# Display the updated data DataFrame\n",
    "print(data.tail(4))\n",
    "\n",
    "# Save the updated DataFrame to a new PKL file if needed\n",
    "data.to_pickle(db_file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "# Define the file path\n",
    "file_path = \"/Users/kaycei/K on Server (NoMachine)/KayCei/Naturalistic_cleaned.pkl\"\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "df = pd.read_pickle(file_path)\n",
    "\n",
    "# Remove the last row using drop with axis=0\n",
    "df = df.drop(df.index[-1], axis=0)\n",
    "\n",
    "# Save the modified DataFrame back to the pickle file\n",
    "df.to_pickle(file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "#If on home machine \n",
    "file_path = \"/Users/kaycei/K on Server (NoMachine)/KayCei/Naturalistic_cleaned.pkl\"\n",
    "#If on Lab Computer \n",
    "#file_path=\"K:/KayCei/Naturalistic.pkl\"\n",
    "try:\n",
    "    df = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Print all rows of the DataFrame\n",
    "    with pd.option_context('display.max_rows', None):\n",
    "        print(df)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
